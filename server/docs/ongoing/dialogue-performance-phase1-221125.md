# Dialogue Performance Optimization - Phase 1

**Date:** November 22, 2025  
**Status:** âœ… Completed

---

## Goal

Reduce response time from **15-19 seconds** to **10-12 seconds** (30% improvement).

---

## Optimizations Implemented

### **Step 1.1: Skip Translation Detection for Same Language** âš¡

**Problem:** LLM was called to detect language even when obvious (Hebrew text â†’ Hebrew language)

**Solution:** Simple heuristic to detect language upfront
```typescript
if (!context.detectedInputLanguage) {
    // Check for Hebrew characters
    const hasHebrew = /[\u0590-\u05FF]/.test(userMessage);
    context.detectedInputLanguage = hasHebrew ? 'he' : 'en';
}
```

**Expected Savings:** ~2-3 seconds (skip 1 LLM call in PlacesLangGraph)

---

### **Step 1.2: Run Call 1 + Call 2 in Parallel** âš¡âš¡

**Problem:** Sequential LLM calls
```
Before:
Call 1 (Intent Analysis): 4s
â†’ Wait
Call 2 (UI Generation): 3s
Total: 7s
```

**Solution:** Run both in parallel using `Promise.all()`
```typescript
const [analysis, response] = await Promise.all([
    this.llm.complete(analysisMessages, { temperature: 0.3 }),
    this.llm.completeJSON(formatMessages, DialogueResponseSchema, { temperature: 0.7 })
]);
```

**Expected Savings:** ~3 seconds (parallel execution)

**After:**
```
Call 1 + Call 2 (parallel): max(4s, 3s) = 4s
Total: 4s
```

---

### **Step 1.3: Cache Language Detection in Session** âš¡

**Problem:** Every message re-detects language

**Solution:** Store detected language in `DialogueContext`
```typescript
export interface DialogueContext {
    // ... existing fields
    detectedInputLanguage?: string; // Cache for detected language
}
```

**Expected Savings:** ~2 seconds per refinement (skip detection on subsequent messages)

---

## Implementation Details

### Files Changed

1. **`server/src/services/dialogue/dialogue.types.ts`**
   - Added `detectedInputLanguage?: string` to `DialogueContext`

2. **`server/src/services/dialogue/dialogue.service.ts`**
   - Added language detection heuristic (Hebrew regex)
   - Changed sequential LLM calls to parallel (`Promise.all`)
   - Cache language in context

---

## Expected Performance

### Before (Sequential + No Cache)
```
1. Call 1 (Intent): 4s
2. Call 2 (UI): 3s
3. PlacesLangGraph:
   - Translation detection: 2s
   - Intent: 3s
   - Result translation: 3s
Total: 15s
```

### After (Parallel + Cache)
```
1. Language detection (heuristic): 0s
2. Call 1 + Call 2 (parallel): 4s
3. PlacesLangGraph:
   - Translation detection: SKIPPED (cached)
   - Intent: 3s
   - Result translation: 3s
Total: 10s
```

**Improvement: 5 seconds (33% faster!)**

---

## Test Scenarios

### Test 1: First Message (Hebrew)
```
User: "××¡×¢×“×ª ×”××‘×•×¨×’×¨×™× ×‘×’×“×¨×”"

Expected:
- Detect language: he (instant, regex)
- Call 1 + 2: ~4s (parallel)
- PlacesLangGraph: ~6s
Total: ~10s (vs 15s before)
```

### Test 2: Refinement (Hebrew)
```
User: "×™×© ××©×”×• ×¤×ª×•×— ×¢×›×©×™×•?"

Expected:
- Language: he (cached, instant)
- Call 1 + 2: ~4s (parallel)
- PlacesLangGraph: ~6s
Total: ~10s (vs 15s before)
```

### Test 3: Multiple Refinements
```
User: "×”××‘×•×¨×’×¨ ×‘×’×“×¨×”" â†’ 10s
User: "×¤×ª×•×— ×¢×›×©×™×•" â†’ 10s (language cached)
User: "×¢× ×—× ×™×”" â†’ 10s (language cached)

All use cached language!
```

---

## Logs to Check

### Before Optimization
```
[DialogueService] Call 1 - Intent Analysis: (4s)
[DialogueService] Call 2 - UI Response: (3s after Call 1)
[PlacesLangGraph] translation result: (2s)
Total: ~15-19s
```

### After Optimization
```
[DialogueService] Detected input language: he (instant)
[DialogueService] Call 1 - Intent Analysis: (4s)
[DialogueService] Call 2 - UI Response: (parallel, same 4s)
[PlacesLangGraph] (should be faster)
Total: ~10-12s
```

---

## Next Steps (Phase 2)

If Phase 1 works well:

1. **Step 2.1:** Single LLM call with full schema (merge Call 1 + 2)
2. **Step 2.2:** Skip PlacesLangGraph intent (use DialogueService intent directly)

**Expected:** 6-8 seconds total (60% faster than original!)

---

## Rollback Plan

If performance is worse or accuracy drops:

```bash
git revert HEAD
```

All changes are in one commit for easy rollback.

---

## Success Criteria

âœ… Response time: 10-12 seconds (down from 15-19s)  
âœ… Accuracy: Same as before (no regressions)  
âœ… Language detection: Correct for Hebrew and English  

---

## Conclusion

Phase 1 optimizations focus on **low-risk, high-impact** changes:
- Parallel execution (free performance)
- Simple caching (no complexity)
- Heuristic detection (fast and accurate for Hebrew/English)

**Ready to test!** ğŸš€


